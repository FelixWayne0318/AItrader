#!/usr/bin/env python3
"""
æ£€æŸ¥æœ€è¿‘è¢«é£æ§é˜»æ­¢çš„ä¿¡å·

åˆ†ææ—¥å¿—å’Œä¿¡å·å†å²ï¼Œæ‰¾å‡ºï¼š
1. AI åŸæœ¬å‘å‡ºçš„ä¿¡å·ï¼ˆLONG/SHORTï¼‰
2. æ˜¯å¦å› ä¸º S/R é£æ§è¢«é˜»æ­¢
3. é˜»æ­¢æ—¶çš„ä»·æ ¼å’Œå¸‚åœºæƒ…å†µ

ç”¨æ³•:
    python3 scripts/check_blocked_signals.py
    python3 scripts/check_blocked_signals.py --log /path/to/journal.log
"""

import os
import sys
import json
import argparse
import re
from datetime import datetime, timedelta
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° path
sys.path.insert(0, str(Path(__file__).parent.parent))

def load_env():
    """åŠ è½½ç¯å¢ƒå˜é‡"""
    env_path = Path.home() / ".env.aitrader"
    if env_path.exists():
        with open(env_path) as f:
            for line in f:
                line = line.strip()
                if line and not line.startswith('#') and '=' in line:
                    key, value = line.split('=', 1)
                    os.environ.setdefault(key.strip(), value.strip())

def parse_journal_logs(log_content: str) -> list:
    """è§£æ journalctl æ—¥å¿—ï¼Œæ‰¾å‡ºè¢«é˜»æ­¢çš„ä¿¡å·"""
    blocked_signals = []

    # åŒ¹é…è¢«é˜»æ­¢çš„ä¿¡å·
    # æ ¼å¼: âš ï¸ LONG blocked: ... æˆ– âš ï¸ SHORT blocked: ...
    block_pattern = re.compile(
        r'(\d{4}-\d{2}-\d{2}\s+\d{2}:\d{2}:\d{2})?.*?'
        r'âš ï¸\s*(LONG|SHORT)\s+blocked:\s*(.+?)(?:\n|$)',
        re.IGNORECASE
    )

    # ä¹ŸåŒ¹é…æ—¥å¿—ä¸­çš„ Blocked: è®°å½•
    blocked_pattern = re.compile(
        r'(\d{4}-\d{2}-\d{2}\s+\d{2}:\d{2}:\d{2})?.*?'
        r'Blocked:\s*(LONG|SHORT)\s+blocked:\s*(.+?)(?:\n|$)',
        re.IGNORECASE
    )

    for match in block_pattern.finditer(log_content):
        timestamp = match.group(1) or "Unknown"
        direction = match.group(2).upper()
        reason = match.group(3).strip()
        blocked_signals.append({
            'timestamp': timestamp,
            'original_signal': direction,
            'blocked_to': 'HOLD',
            'reason': reason,
        })

    return blocked_signals

def analyze_signal_history(logs_dir: Path) -> list:
    """åˆ†æä¿¡å·å†å²æ–‡ä»¶"""
    blocked = []

    # æ£€æŸ¥ signal_history.json
    signal_history_file = logs_dir / "signal_history.json"
    if signal_history_file.exists():
        try:
            with open(signal_history_file) as f:
                history = json.load(f)

            for entry in history:
                reason = entry.get('reason', '')
                if 'Blocked:' in reason:
                    blocked.append({
                        'timestamp': entry.get('timestamp', 'Unknown'),
                        'signal': entry.get('signal', 'HOLD'),
                        'reason': reason,
                        'confidence': entry.get('confidence', 'N/A'),
                    })
        except Exception as e:
            print(f"âš ï¸ è¯»å– signal_history.json å¤±è´¥: {e}")

    return blocked

def get_recent_journal_logs(hours: int = 24) -> str:
    """è·å–æœ€è¿‘çš„ journalctl æ—¥å¿—"""
    import subprocess

    try:
        # è·å–æœ€è¿‘ N å°æ—¶çš„æ—¥å¿—
        result = subprocess.run(
            ['journalctl', '-u', 'nautilus-trader', '--no-hostname',
             '--since', f'{hours} hours ago', '--no-pager'],
            capture_output=True,
            text=True,
            timeout=30
        )
        return result.stdout
    except subprocess.TimeoutExpired:
        print("âš ï¸ journalctl è¶…æ—¶")
        return ""
    except FileNotFoundError:
        print("âš ï¸ journalctl ä¸å¯ç”¨ï¼ˆå¯èƒ½ä¸åœ¨æœåŠ¡å™¨ä¸Šï¼‰")
        return ""
    except Exception as e:
        print(f"âš ï¸ è·å–æ—¥å¿—å¤±è´¥: {e}")
        return ""

def analyze_price_movement(hours: int = 24) -> dict:
    """åˆ†ææœ€è¿‘çš„ä»·æ ¼èµ°åŠ¿"""
    import requests

    try:
        # è·å–æœ€è¿‘çš„ K çº¿æ•°æ®
        end_time = int(datetime.now().timestamp() * 1000)
        start_time = int((datetime.now() - timedelta(hours=hours)).timestamp() * 1000)

        url = "https://fapi.binance.com/fapi/v1/klines"
        params = {
            'symbol': 'BTCUSDT',
            'interval': '1h',
            'startTime': start_time,
            'endTime': end_time,
            'limit': hours + 1
        }

        response = requests.get(url, params=params, timeout=10)
        response.raise_for_status()
        klines = response.json()

        if not klines:
            return {}

        # è®¡ç®—ä»·æ ¼å˜åŒ–
        first_close = float(klines[0][4])
        last_close = float(klines[-1][4])
        high = max(float(k[2]) for k in klines)
        low = min(float(k[3]) for k in klines)

        change_pct = (last_close - first_close) / first_close * 100

        return {
            'start_price': first_close,
            'end_price': last_close,
            'high': high,
            'low': low,
            'change_pct': change_pct,
            'hours': hours,
        }
    except Exception as e:
        print(f"âš ï¸ è·å–ä»·æ ¼æ•°æ®å¤±è´¥: {e}")
        return {}

def check_should_have_shorted(price_data: dict, blocked_signals: list) -> list:
    """åˆ†ææ˜¯å¦åº”è¯¥åšç©ºä½†è¢«é˜»æ­¢"""
    missed_opportunities = []

    if not price_data:
        return missed_opportunities

    change_pct = price_data.get('change_pct', 0)

    # å¦‚æœä»·æ ¼ä¸‹è·Œè¶…è¿‡ 2%ï¼Œæ£€æŸ¥æ˜¯å¦æœ‰ SHORT è¢«é˜»æ­¢
    if change_pct < -2:
        for signal in blocked_signals:
            if signal.get('original_signal') == 'SHORT' or 'SHORT blocked' in signal.get('reason', ''):
                missed_opportunities.append({
                    **signal,
                    'market_move': f"ä»·æ ¼ä¸‹è·Œ {abs(change_pct):.2f}%",
                    'potential_profit': f"å¯èƒ½é”™è¿‡ {abs(change_pct):.1f}% ç›ˆåˆ©",
                })

    return missed_opportunities

def main():
    parser = argparse.ArgumentParser(description='æ£€æŸ¥è¢«é£æ§é˜»æ­¢çš„ä¿¡å·')
    parser.add_argument('--hours', type=int, default=48, help='åˆ†ææœ€è¿‘å‡ å°æ—¶ (é»˜è®¤: 48)')
    parser.add_argument('--log', type=str, help='æŒ‡å®šæ—¥å¿—æ–‡ä»¶è·¯å¾„')
    args = parser.parse_args()

    print("=" * 70)
    print("ğŸ” S/R é£æ§é˜»æ­¢ä¿¡å·æ£€æŸ¥")
    print("=" * 70)

    load_env()

    # 1. è·å–ä»·æ ¼èµ°åŠ¿
    print(f"\nğŸ“Š åˆ†ææœ€è¿‘ {args.hours} å°æ—¶ä»·æ ¼èµ°åŠ¿...")
    price_data = analyze_price_movement(args.hours)

    if price_data:
        change = price_data['change_pct']
        direction = "ğŸ“ˆ ä¸Šæ¶¨" if change > 0 else "ğŸ“‰ ä¸‹è·Œ"
        print(f"\n{direction} {abs(change):.2f}%")
        print(f"  èµ·å§‹: ${price_data['start_price']:,.2f}")
        print(f"  å½“å‰: ${price_data['end_price']:,.2f}")
        print(f"  æœ€é«˜: ${price_data['high']:,.2f}")
        print(f"  æœ€ä½: ${price_data['low']:,.2f}")

    # 2. è·å–æ—¥å¿—
    print(f"\nğŸ“‹ è·å–æœ€è¿‘ {args.hours} å°æ—¶çš„æ—¥å¿—...")

    if args.log and Path(args.log).exists():
        with open(args.log) as f:
            log_content = f.read()
    else:
        log_content = get_recent_journal_logs(args.hours)

    # 3. è§£æè¢«é˜»æ­¢çš„ä¿¡å·
    blocked_signals = parse_journal_logs(log_content)

    # 4. æ£€æŸ¥ä¿¡å·å†å²æ–‡ä»¶
    logs_dir = Path(__file__).parent.parent / "logs"
    history_blocked = analyze_signal_history(logs_dir)

    print("\n" + "=" * 70)
    print("ğŸ“Š è¢«é˜»æ­¢çš„ä¿¡å·ç»Ÿè®¡")
    print("=" * 70)

    if blocked_signals:
        print(f"\nä»æ—¥å¿—ä¸­å‘ç° {len(blocked_signals)} ä¸ªè¢«é˜»æ­¢çš„ä¿¡å·:")
        for i, sig in enumerate(blocked_signals[-10:], 1):  # æœ€è¿‘ 10 ä¸ª
            print(f"\n  {i}. [{sig['timestamp']}]")
            print(f"     åŸä¿¡å·: {sig['original_signal']} â†’ è¢«æ”¹ä¸º: HOLD")
            print(f"     åŸå› : {sig['reason']}")
    else:
        print("\nâœ… æ—¥å¿—ä¸­æœªå‘ç°è¢«é˜»æ­¢çš„ä¿¡å·")

    if history_blocked:
        print(f"\nä»ä¿¡å·å†å²ä¸­å‘ç° {len(history_blocked)} ä¸ªè¢«é˜»æ­¢çš„è®°å½•:")
        for i, sig in enumerate(history_blocked[-10:], 1):
            print(f"\n  {i}. [{sig['timestamp']}]")
            print(f"     ä¿¡å·: {sig['signal']}, ä¿¡å¿ƒ: {sig['confidence']}")
            print(f"     åŸå› : {sig['reason'][:100]}...")

    # 5. åˆ†æé”™è¿‡çš„æœºä¼š
    print("\n" + "=" * 70)
    print("ğŸ’° é”™è¿‡çš„åšç©ºæœºä¼šåˆ†æ")
    print("=" * 70)

    all_blocked = blocked_signals + [
        {'original_signal': 'SHORT' if 'SHORT blocked' in b.get('reason', '') else 'LONG',
         'reason': b.get('reason', ''),
         'timestamp': b.get('timestamp', '')}
        for b in history_blocked
    ]

    missed = check_should_have_shorted(price_data, all_blocked)

    if missed:
        print(f"\nâš ï¸ å‘ç° {len(missed)} ä¸ªå¯èƒ½é”™è¿‡çš„åšç©ºæœºä¼š:")
        for i, m in enumerate(missed, 1):
            print(f"\n  {i}. [{m.get('timestamp', 'N/A')}]")
            print(f"     {m.get('market_move', 'N/A')}")
            print(f"     {m.get('potential_profit', 'N/A')}")
            print(f"     é˜»æ­¢åŸå› : {m.get('reason', 'N/A')[:80]}...")
    else:
        if price_data.get('change_pct', 0) < -2:
            print(f"\nâš ï¸ ä»·æ ¼ä¸‹è·Œäº† {abs(price_data['change_pct']):.2f}%ï¼Œä½†æœªå‘ç°è¢«é˜»æ­¢çš„ SHORT ä¿¡å·")
            print("   å¯èƒ½åŸå› :")
            print("   1. AI æœ¬èº«åˆ¤æ–­ä¸º HOLDï¼Œä¸æ˜¯å› ä¸ºé£æ§")
            print("   2. æ—¥å¿—è®°å½•ä¸å®Œæ•´")
            print("   3. æœåŠ¡å½“æ—¶æœªè¿è¡Œ")
        else:
            print("\nâœ… ä»·æ ¼æœªå¤§å¹…ä¸‹è·Œï¼Œæ— æ˜æ˜¾é”™è¿‡çš„åšç©ºæœºä¼š")

    # 6. å»ºè®®
    print("\n" + "=" * 70)
    print("ğŸ’¡ å»ºè®®")
    print("=" * 70)

    if missed or (price_data.get('change_pct', 0) < -3):
        print("""
  âš ï¸ 15 åˆ†é’Ÿ S/R é£æ§å¯èƒ½è¿‡äºæ•æ„Ÿ:

  é—®é¢˜: 15 åˆ†é’Ÿæ”¯æ’‘ä½åœ¨å¤§è·Œæ—¶ä¸æ–­è¢«çªç ´ï¼Œ
        ä½†é£æ§ä»ç„¶é˜»æ­¢åšç©ºï¼ˆå› ä¸ºä»·æ ¼æ¥è¿‘æ”¯æ’‘ï¼‰

  è§£å†³æ–¹æ¡ˆ:
  1. ç¦ç”¨ S/R ç¡¬é£æ§ (æ¨èæµ‹è¯•)
  2. æ”¹ç”¨æ›´é«˜å‘¨æœŸçš„ S/R (4H/1D)
  3. åªåœ¨ Order Wall å­˜åœ¨æ—¶æ‰é˜»æ­¢

  ç¦ç”¨å‘½ä»¤:
  åœ¨ agents/multi_agent_analyzer.py ä¸­æ³¨é‡Šæ‰ _evaluate_risk çš„é£æ§é€»è¾‘
        """)
    else:
        print("\n  å½“å‰é£æ§è¡¨ç°æ­£å¸¸ï¼Œæš‚æ— éœ€è°ƒæ•´")

if __name__ == '__main__':
    main()
